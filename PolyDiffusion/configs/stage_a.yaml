vocab_path: vocab.txt
model_config: configs/model_base.yaml

# Results directory for checkpoints
results_dir: Results/stage_a

data:
  path: data/molecules.jsonl.gz
  limit: null  # Use full dataset, or set integer to use subset
  shuffle: true
  cache_in_memory: true
  seed: 42

training:
  batch_size: 2048
  lr: 3.0e-4
  lr_min: 1.0e-6  # Minimum LR for cosine annealing scheduler
  weight_decay: 0.01
  steps: 1000
  log_interval: 50
  save_interval: 500  # Save checkpoint every 500 steps
  max_grad_norm: 1.0  # Gradient clipping
  num_workers: 4
  pin_memory: true

loss:
  lambda_syn: 0.5

# Optional: Resume from checkpoint if training interrupted
# resume_checkpoint: Results/stage_a/checkpoint_step_500.pt
